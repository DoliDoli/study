{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 今回の目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ReNom習得に向けて必要な知識を伝授する\n",
    "- Deep Learningの全体感と専門用語を知ってもらい、独学で勉強する時のの土台にしてもらう  \n",
    "\n",
    "__＊　数式的な解説は私は全くできません__　　\n",
    "__＊　技術の解説は別途やります　__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.Deep Learningざっくり説明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 機械学習手法の一つである「ニューラルネットワーク」を多層に組み合わせたもの\n",
    "・3層以上のニューラルネット  \n",
    "・別名「多層ニューラルネットワーク」「深層ニューラルネットワーク」「DNN」  \n",
    "・今15層くらいのやつとかある  \n",
    "\n",
    "#### 事例\n",
    "- 一番簡単なのは手書き文字認識\n",
    "- 画像認識で顕著\n",
    "    - 2012年・画像認識の世界大会でぶっちぎる\n",
    "        - http://www.slideshare.net/pfi/deep-learning-22350063\n",
    "        - 認識精度95%くらい(100クラス分類)\n",
    "- 猫の画像・人の顔を自動で認識\n",
    "    - http://www.slideshare.net/kazoo04/deep-learning-15097274\n",
    "    - http://www.vision.is.tohoku.ac.jp/files/9313/6601/7876/CVIM_tutorial_deep_learning.pdf\n",
    "- 画風変換\n",
    "    - https://research.preferred.jp/2015/09/chainer-gogh/\n",
    "    - http://fvae.ail.tokyo/\n",
    "- モノクロ画像への着色\n",
    "    - https://blog.misosi.ru/2016/06/04/siggraph2016_colorization_web_impl/　  \n",
    "- 自然言語処理でも\n",
    "    - チャットボット「りんな」\n",
    "    - 今度部会で話す「オシエル」\n",
    "        - http://oshiete.goo.ne.jp/ai\n",
    "- Googleの音楽を自動生成とか\n",
    "- 「AlphaGo」世界3位の囲碁棋士に勝利\n",
    "    - ルールを人間が教えることなくDeepLearningのみで勝利\n",
    "        - http://wired.jp/2016/03/16/final-round/　　\n",
    "        \n",
    "#### Deep Learningのデモが見れるサイト\n",
    "- A Neural Network Playground\n",
    "    - http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.75865&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\n",
    "- ConvNetJS\n",
    "    - http://cs.stanford.edu/people/karpathy/convnetjs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.機械学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 機械学習概要\n",
    "- http://www.slideshare.net/unnonouno/jubatus-casual-talks\n",
    "    - スパム判定・商品レコメンド・チェス\n",
    "    - 計算が早い、大量のデータを処理できる\n",
    "- 機械に自動で目的を達成してもらう\n",
    "    - データから知識を自動で獲得するアルゴリズム\n",
    "    - 入力に対して自動で目的のものを出力する\n",
    "    - 入力はベクトル（特徴ベクトル）\n",
    "    - 実装する際はベクトルをまとめて入力する = 行列\n",
    "- 線形分離の例　＝　目的に合致した関数を自動で機械の計算で自動で作成\n",
    "    - 重み・バイアスがはいる\n",
    "    - 重み・バイアスを用い正解との誤差を計算する「損失関数・loss」を最小にするようにパラメータを機械が自動で更新する\n",
    "    - 機械学習でいうところの「目的関数」\n",
    "    - 結局　損失関数の最適化問題に帰結する\n",
    "  \n",
    "#### 教師あり学習\n",
    "- 分類（Classiication）\n",
    "    - 線形分離\n",
    "    - ロジスティック回帰\n",
    "    - 決定木（Decision Forest）\n",
    "    - ランダムフォレスト\n",
    "    - K 近傍法\n",
    "    - サポートベクターマシン（SVM）\n",
    "- 回帰\n",
    "    - 線形回帰　　\n",
    "    \n",
    "#### 教師なし学習\n",
    "- クラスタリング\n",
    "    - K-means\n",
    "    - 階層的クラスタリング\n",
    "    - トピックモデル（LDA）\n",
    "- 次元圧縮\n",
    "    - 主成分分析　　\n",
    "    \n",
    "#### 強化学習\n",
    "- 動的計画法\n",
    "- Q学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.パーセプトロン・ニューラルネット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パーセプトロン\n",
    "- よくある例「出社するのかしないのか」的な\n",
    "    - http://nnadl-ja.github.io/nnadl_site_ja/chap1.html\n",
    "- 入力と重みをシグマする\n",
    "    - http://qiita.com/Ugo-Nama/items/04814a13c9ea84978a4c\n",
    "- 入出力ともに0,1しかとらない  \n",
    "\n",
    "#### シグモイドニューロン\n",
    "- 入力に小数を用いることができる\n",
    "- 出力にシグモイド関数（たぶん活性化関数）をかけて少数を表す\n",
    "- ニューロンそれぞれが　f(w・x+b)\n",
    "  \n",
    "#### ニューラルネット\n",
    "- ニューラルネットとは「脳の神経細胞ニューロンの構造を真似て作成したもので、複数のニューロンが存在する層を積層し、異なる層のニューロンを接続して信号を伝達します。」\n",
    "- 入力層・出力層・隠れ層\n",
    "    - http://neural-network.net/?p=7\n",
    "    - http://www.impressbm.co.jp/event/datascientist2016spring/images/2015autumn_pdf5.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Deep Learningとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepLearningって何できるの？\n",
    "- 高次元データに対する高精度機械学習\n",
    "    - 基本的には「分類」「回帰」　→　教師あり学習\n",
    "    - 教師なしも強化学習もできる\n",
    "- 特徴量をこっちで（細かく）設定せずに使えるのが便利\n",
    "- 派生的な使い方\n",
    "    - 特徴抽出\n",
    "        - Google猫画像\n",
    "    - 生成モデル\n",
    "        - DCGAN\n",
    "        - VAE\n",
    "    - 強化学習\n",
    "        - DQN  \n",
    "                \n",
    "#### 誤差の計算方法\n",
    "- 回帰は「平均2乗誤差」\n",
    "- 分類は「クロスエントロピー」\n",
    "    - 出力結果にSoftMax関数をかませることで、分類問題に適用させる\n",
    "- DeepLearningの目的は、重みとバイアスによる2次関数である「損失関数」関数を最小化する\n",
    "    - 勾配降下法を用いて最適化\n",
    "- データを「学習用データ」「検証用データ」にわけ、精度を検証する\n",
    "    - まったく学習していない検証用データをモデルを使い分類させてみたりする\n",
    "    - 過学習を防ぐ\n",
    "  \n",
    "#### 活性化関数\n",
    "- http://www.slideshare.net/spade630/ss-51681817\n",
    "- 活性化関数の意味\n",
    "    - 各ニューロンの出力を活性化関数で正規化すると結果がよくなる、と知られている\n",
    "    - Sigmoid\n",
    "    - relu\n",
    "    - tanh\n",
    "    - 線形写像\n",
    "    - maxout\n",
    "  \n",
    "#### 順伝搬\n",
    "- 情報を流し、損失関数をつくる？\n",
    "- 誤差逆伝搬（バックプロパゲーション）\n",
    "    - 結果・誤差を把握し、結果から損失関数の勾配を「効率的に」計算する方法  \n",
    "    \n",
    "#### 勾配\n",
    "- 損失関数の傾きのこと\n",
    "    - あまりにDNNを多層にすると勾配消失問題・勾配爆発問題が発生  \n",
    "    \n",
    "#### 確率的勾配降下法\n",
    "- 損失関数を最小にするアルゴリズム\n",
    "- 一部分ずつサンプルとってきて、順次損失関数を最適化する手法\n",
    "- 最適化（Optimize）するアルゴリズム\n",
    "    - 略称はSGD\n",
    "- これ以外にも「Adam」「AdaGrad」「RMSprop」「Momentam」などがある  \n",
    "\n",
    "#### DropOut\n",
    "- 精度をよくするおまじない\n",
    "    - データの正規化というおまじないも役に立つ\n",
    "- ニューロン同士の結合を一部なくすことで、逆に精度がよくなることが知られている\n",
    "    - 限られた情報の中で最大限特徴を抽出しようとするため"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Deep Learningのバリエーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "近年は、下記の色々なネットワークを組み合わせたりして機能を実現している  \n",
    "全結合型ニューラルネット：分類・回帰\n",
    "#### CNN\n",
    "- 主に画像データを扱うためのモデル\n",
    "    - http://www.slideshare.net/ssuser726f56/joi-51681753?qid=76177910-e2ca-4b1c-ae98-a4917c36b164&v=&b=&from_search=7\n",
    "    - http://www.slideshare.net/matsukenbook/ss-50545587(これがすべて)\n",
    "- 用途\n",
    "    - 画像認識\n",
    "    - 特徴抽出  \n",
    "    \n",
    "#### RNN\n",
    "- 主に時系列データを扱うためのモデル\n",
    "    - http://www.slideshare.net/beam2d/pfi-seminar-20141030rnn?qid=be62e9f6-db90-4586-b44e-ab6e35185177&v=&b=&from_search=12\n",
    "- LSTM\n",
    "    - http://qiita.com/t_Signull/items/21b82be280b46f467d1b\n",
    "- よく似たものに「Recursive Neural Network」というものがある\n",
    "    - こちらは覚えなくて大丈夫\n",
    "- 用途\n",
    "    - 文章生成\n",
    "        - 画像説明文生成とか\n",
    "    - 機械翻訳\n",
    "    - センサーデータ分析\n",
    "    - 動画分析  \n",
    "    \n",
    "#### AE\n",
    "- 入力層を出力層で再現するネットワーク\n",
    "    - SAE\n",
    "    - DeNoising AE\n",
    "- 事前学習・転移学習に使われる\n",
    "- 生成モデルの基礎になっている  \n",
    "\n",
    "#### Restricted Boltzman Machine\n",
    "- たぶん事前学習に使っている　程度の認識  \n",
    "\n",
    "#### DCGAN\n",
    "- DeepLearningを用いて画像生成\n",
    "    - http://memo.sugyan.com/entry/20160516/1463359395\n",
    "    - http://memo.sugyan.com/entry/2016/10/12/084751  \n",
    "    \n",
    "#### DQN\n",
    "    - http://qiita.com/Ugo-Nama/items/08c6a5f6a571335972d5\n",
    "    - Atariのゲーム攻略\n",
    "    - https://www.youtube.com/watch?v=V1eYniJ0Rnk  \n",
    "    \n",
    "#### Alpha Go\n",
    "    - http://wired.jp/2016/03/15/the-mystery-of-go/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Deep Learningを実装する技術"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "OSとしてはLinux(Ubuntu)が推奨\n",
    "- 環境構築が死ぬほど辛い\n",
    "- Mac（Unixでも可）\n",
    "- Windowsに入れようとすると地獄、まったくお勧めできない  \n",
    "  \n",
    "言語はPythonがメジャー\n",
    "- 関連ライブラリ\n",
    "    - Numpy\n",
    "    - Scipy\n",
    "    - Pandas\n",
    "- 各言語にDeepLearning実装用のライブラリがある\n",
    "- 結局すべては「グラフ計算を実現する」ライブラリ\n",
    "    - https://speakerdeck.com/rindai87/talk-about-ml-and-dl-for-happy-engineers-life  \n",
    "    \n",
    "#### 各フレームワーク比較\n",
    "- http://qiita.com/aokikenichi/items/c359a53e8307be3ebe02\n",
    "- http://qiita.com/jintaka1989/items/bfcf9cc9b0c2f597d419\n",
    "- Caffe\n",
    "- Chainer\n",
    "- Tensorflow\n",
    "- Keras\n",
    "\n",
    "#### GPU（CPUのスゴイ版）を搭載しているマシンが望ましい\n",
    "- 学習の収束までの時間が段違い\n",
    "- GPUを使用するためにはPCに特別な設定が必要\n",
    "- CUDAを用いたプログラミングも必要（ライブラリによっては不要）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次回"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - 実装方法やプログラムの解説をしたほうがいいと思う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他.情報収集に役にたつサイト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Qiita　　http://qiita.com/\n",
    "  - 技術・理論的情報が集約\n",
    "- AI NOW 　http://ainow.ai/\n",
    "  - AI系ニュースポータル\n",
    "- 知ってたほうがいいこと\n",
    "  - Word2Vec\n",
    "  - Chainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他参考資料メモ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://www.impressbm.co.jp/event/datascientist2016spring/images/2015autumn_pdf5.pdf\n",
    "- http://www.slideshare.net/yomoyamareiji/ss-36982686?qid=76177910-e2ca-4b1c-ae98-a4917c36b164&v=&b=&from_search=5\n",
    "- https://drive.google.com/file/d/0B04ol8GVySUuMUx2MHJUWjVGQ2s/view"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
